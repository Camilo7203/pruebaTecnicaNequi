{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "925e5ada52413c72",
   "metadata": {},
   "source": [
    "# EDA Exploratory Data Analysis\n",
    "## DataSet StackSample: 10% of Stack Overflow Q&A\n",
    "https://www.kaggle.com/datasets/stackoverflow/stacksample\n",
    "\n",
    "### Motivacion\n",
    "Escogi este dataset porque es un dataset de preguntas y respuestas de temas tecnicos, en donde se puede hacer una solucion NLP con base a las tags que ya se tienen, para entrenar un modelo de clasificacion de texto.\n",
    "\n",
    "### Descripcion del data set\n",
    "El data set contiene 3 archivos que son:\n",
    "* **Questions.csv**: Contiene las preguntas de stackoverflow y tiene la siguiente estructura\n",
    "    * Id: Identificador de la pregunta\n",
    "    * OwnerUserId: Identificador del usuario que pregunta\n",
    "    * CreationDate: Fecha de creacion de la pregunta\n",
    "    * ClosedDate: Fecha de cierre de la pregunta\n",
    "    * Score: Puntuacion de la pregunta\n",
    "    * Title: Titulo de la pregunta\n",
    "    * Body: Cuerpo de la pregunta\n",
    "* **Answers.csv**: Contiene las respuestas de las preguntas y tiene la siguiente estructura\n",
    "    * Id: Identificador de la respuesta\n",
    "    * OwnerUserId: Identificador del usuario que responde\n",
    "    * CreationDate: Fecha de creacion de la respuesta\n",
    "    * ParentId: Identificador de la pregunta a la que responde\n",
    "    * Score: Puntuacion de la respuesta\n",
    "    * Body: Cuerpo de la respuesta\n",
    "* **Tags.csv**: Contiene las etiquetas de las preguntas y tiene la siguiente estructura\n",
    "    * Id: Identificador de la etiqueta\n",
    "    * Tag: Nombre de la etiqueta\n",
    "\n",
    "\n",
    "### Objetivo\n",
    "El objetivo de este notebook es hacer un analisis exploratorio de los datos, para ver que tipo de datos tenemos y como podemos utilizarlos para entrenar un modelo de clasificacion de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b3bdb6269c6843",
   "metadata": {},
   "source": [
    "### Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "id": "93c5fdf34794d3cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T17:15:14.994928Z",
     "start_time": "2025-05-19T17:15:14.988552Z"
    }
   },
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "eb883dbde36a6521",
   "metadata": {},
   "source": [
    "### Importar los datos"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T17:15:15.013195Z",
     "start_time": "2025-05-19T17:15:15.008085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_data(file_path):\n",
    "    \"\"\"\n",
    "    Lee un archivo CSV y lo carga en un DataFrame de pandas.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    file_path: str\n",
    "        Ruta al archivo CSV que se desea leer.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame con los datos cargados desde el archivo CSV.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path, encoding=\"ISO-8859-1\")\n",
    "    return data"
   ],
   "id": "42f398cc544a7ff6",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T17:15:15.027539Z",
     "start_time": "2025-05-19T17:15:15.023706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_dfs_info(*dfs):\n",
    "    \"\"\"\n",
    "    Muestra información básica de uno o varios DataFrames.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    *dfs: pandas.DataFrame\n",
    "        Uno o varios DataFrames cuyos detalles se desean imprimir.\n",
    "\n",
    "    Comportamiento\n",
    "    -------------\n",
    "    Para cada DataFrame recibido, imprime:\n",
    "    - Un encabezado indicando el número de orden del DataFrame.\n",
    "    - La longitud (número de filas).\n",
    "    - El resultado de `df.info()` con resumen de columnas, tipos y memoria.\n",
    "    \"\"\"\n",
    "    for i, df in enumerate(dfs, 1):\n",
    "        print(f\"--- DataFrame {i} ---\")\n",
    "        print(\"length:\", len(df))\n",
    "        df.info()\n",
    "        print(\"\\n\")"
   ],
   "id": "9f7d02dbe4a290c1",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T17:15:15.043687Z",
     "start_time": "2025-05-19T17:15:15.037673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def review_data_quality(questions, answers, tags):\n",
    "    \"\"\"\n",
    "    Revisa y reporta la calidad de tres DataFrames: preguntas, respuestas y etiquetas.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    questions : pandas.DataFrame\n",
    "        DataFrame con las preguntas, debe incluir al menos la columna 'Title'.\n",
    "    answers : pandas.DataFrame\n",
    "        DataFrame con las respuestas.\n",
    "    tags : pandas.DataFrame\n",
    "        DataFrame con las etiquetas, debe incluir la columna 'Tag'.\n",
    "\n",
    "    Comportamiento\n",
    "    -------------\n",
    "    - Imprime el conteo de valores nulos en cada DataFrame y en 'Tag'.\n",
    "    - Elimina las filas de `tags` cuyo campo 'Tag' sea nulo.\n",
    "    - Calcula e imprime el número de filas duplicadas en cada DataFrame.\n",
    "    - Verifica y notifica si hay títulos repetidos en `questions['Title']`.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Nulos en questions:\\n\", questions.isnull().sum())\n",
    "    print(\"\\nNulos en answers:\\n\", answers.isnull().sum())\n",
    "    print(\"\\nNulos en tags:\\n\", tags.isnull().sum())\n",
    "    nulos_tag_col = tags['Tag'].isnull().sum()\n",
    "    print(f\"\\nNulos en la columna 'Tag' de tags: {nulos_tag_col}\")\n",
    "\n",
    "    tags = tags.dropna(subset=['Tag'])\n",
    "\n",
    "    duplicated_questions = questions.duplicated().sum()\n",
    "    duplicated_answers = answers.duplicated().sum()\n",
    "    duplicated_tags = tags.duplicated().sum()\n",
    "    print(f\"\\nDuplicados en questions: {duplicated_questions}\")\n",
    "    print(f\"Duplicados en answers: {duplicated_answers}\")\n",
    "    print(f\"Duplicados en tags: {duplicated_tags}\")\n",
    "\n",
    "    duplicated_title = questions['Title'].duplicated().sum()\n",
    "    if duplicated_title > 0:\n",
    "        print(f\"\\nHay {duplicated_title} títulos repetidos en la columna Title.\")\n",
    "    else:\n",
    "        print(\"\\nNo hay títulos repetidos en la columna Title.\")"
   ],
   "id": "38d07cde6c909a8",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T17:15:47.731692Z",
     "start_time": "2025-05-19T17:15:15.057213Z"
    }
   },
   "cell_type": "code",
   "source": "questions = read_data('../data/input/Questions.csv')",
   "id": "ef2266a2531d49e2",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-19T17:15:47.742031Z"
    }
   },
   "cell_type": "code",
   "source": "answers = read_data('../data/input/Answers.csv')",
   "id": "6dda66f3e3a05f81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tags = read_data('../data/input/Tags.csv')",
   "id": "c88a25f5170c0cbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f2474021b4b8176b",
   "metadata": {},
   "source": [
    "### Exploracion de datos"
   ]
  },
  {
   "cell_type": "code",
   "id": "8fec97178c32d690",
   "metadata": {},
   "source": "get_dfs_info(questions, answers, tags)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e03562ebfe4f3e4",
   "metadata": {},
   "source": [
    "questions.head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "313bfe3e6b7be29c",
   "metadata": {},
   "source": [
    "answers.head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "12ac88f1a08f02d5",
   "metadata": {},
   "source": [
    "tags.head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a62ffa9f",
   "metadata": {},
   "source": [
    "### Revision de la calidad de datos"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "review_data_quality(questions, answers, tags)",
   "id": "6e57c3aaf1ca1f6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "questions.isnull().sum()",
   "id": "6aca82c64314d449",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b3627edca95f15eb",
   "metadata": {},
   "source": [
    "### Informacion relevante de los dataframes\n",
    "Despues de ver los dataframes, podemos concluir la siguiente informacion:\n",
    "- **Questions.csv** tiene 3 columnas que son importantes para nuestro analisis, que son:\n",
    "\t- Id: Identificador de la pregunta\n",
    "\t- Title: Titulo de la pregunta\n",
    "\t- Body: Cuerpo de la pregunta\n",
    "- Las demas columnas no son relevantes para nuestro analisis, porque:\n",
    "\t- OwnerUserId: No es relevante porque no nos interesa saber quien hizo la pregunta\n",
    "\t- CreationDate: No es relevante porque no nos interesa saber cuando se hizo la pregunta\n",
    "\t- ClosedDate: No es relevante porque no nos interesa saber cuando se cerro la pregunta\n",
    "\t- Score: No es relevante porque no nos interesa saber la puntuacion de la pregunta\n",
    "- **Tags.csv** las 2 columnas  son importantes para nuestro analisis:\n",
    "\t- Id: Identificador de la etiqueta\n",
    "\t- Tag: Nombre de la etiqueta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2581e8",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Despues de ver la estructura y toda la informacion de el data set, vamos a hacer uso de los archivos **Questions.csv** y el de **Tags.csv**, ya que son las que nos sirve para realziar un analisis de las tags por preguntas, como proximos pasos se podria validad como se comportaria el modelo agregando la iunformacion de **Answers.csv**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

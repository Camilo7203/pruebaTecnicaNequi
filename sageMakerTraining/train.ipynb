{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T20:34:53.940212Z",
     "start_time": "2025-05-19T20:34:53.936031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Librería estándar\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "import glob\n",
    "# Librerías de terceros\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    hamming_loss,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sagemaker import Session, image_uris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56ff92-72e9-4d22-a968-c82dd961219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    \"\"\"\n",
    "    Lee un archivo parquet y lo carga en un DataFrame de pandas.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    file_path: str\n",
    "        Ruta al archivo parquet que se desea leer.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame con los datos cargados desde el archivo parquet.\n",
    "    \"\"\"\n",
    "    data = pd.read_parquet(file_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c72cf-2f2c-4a0d-abdf-d98f588547d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_vectorizer_tfidf(df, col):\n",
    "    \"\"\"\n",
    "    Convierte la columna especificada a string, la vectoriza usando TF-IDF y retorna la matriz y el vectorizador.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    df: pandas.DataFrame\n",
    "        DataFrame que contiene la columna a vectorizar.\n",
    "    col: str\n",
    "        Nombre de la columna de texto.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    X : scipy.sparse.csr.csr_matrix\n",
    "        Matriz TF-IDF.\n",
    "    vectorizer : TfidfVectorizer\n",
    "        Vectorizador entrenado.\n",
    "    \"\"\"\n",
    "    df[col] = df[col].astype(str)\n",
    "    vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "    X = vectorizer.fit_transform(df[col].str.lower())\n",
    "    return X, vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b5f18-85d1-4cd5-9493-6c7cb7778548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(y_pred, clf):\n",
    "    \"\"\"\n",
    "    Imprime métricas de evaluación de clasificación multilabel para un clasificador dado.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    y_pred : array-like\n",
    "        Predicciones generadas por el clasificador.\n",
    "    clf : objeto clasificador\n",
    "        Instancia del modelo utilizado para predecir, se usa solo para mostrar su nombre de clase.\n",
    "\n",
    "    Comportamiento\n",
    "    -------------\n",
    "    - Muestra por consola:\n",
    "      * Nombre de la clase del clasificador.\n",
    "      * Exactitud (accuracy).\n",
    "      * Recall ponderado.\n",
    "      * Precisión ponderada.\n",
    "      * Puntuación F1 ponderada.\n",
    "      * Puntuación de Jaccard promedio (porcentaje).\n",
    "      * Hamming loss en porcentaje.\n",
    "    - Asume que la variable global `y_test` contiene las etiquetas verdaderas.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"Clf: \", clf.__class__.__name__)\n",
    "    print(\"Accuracy score: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "    print(\"Recall score: {}\".format(recall_score(y_true=y_test, y_pred=y_pred, average='weighted')))\n",
    "    print(\"Precision score: {}\".format(precision_score(y_true=y_test, y_pred=y_pred, average='weighted')))\n",
    "    print(\"F1 score: {}\".format(f1_score(y_pred, y_test, average='weighted')))\n",
    "    print(\"Jacard score: {}\".format(avg_jacard(y_test, y_pred)))\n",
    "    print(\"Hamming loss: {}\".format(hamming_loss(y_pred, y_test)*100))\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe0808e-aff8-4350-80c3-4fd807a1f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_top_n_tags(text, vectorizer, classifier, multilabel_binarizer, n=5):\n",
    "    \"\"\"\n",
    "    Predice las n etiquetas más probables para un texto dado.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    text : str\n",
    "        Texto para el cual predecir etiquetas.\n",
    "    vectorizer : TfidfVectorizer\n",
    "        Vectorizador TF-IDF entrenado.\n",
    "    classifier : OneVsRestClassifier\n",
    "        Clasificador entrenado.\n",
    "    multilabel_binarizer : MultiLabelBinarizer\n",
    "        Binarizador de etiquetas utilizado.\n",
    "    n : int\n",
    "        Número máximo de etiquetas a predecir.\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    list\n",
    "        Lista de las n etiquetas más probables.\n",
    "    \"\"\"\n",
    "    # Transformar el texto usando el vectorizador\n",
    "    X = vectorizer.transform([text.lower()])\n",
    "\n",
    "    # Obtener probabilidades para cada clase\n",
    "    y_proba = classifier.predict_proba(X)\n",
    "\n",
    "    # Obtener los índices de las n probabilidades más altas\n",
    "    top_n_indices = y_proba[0].argsort()[-n:][::-1]\n",
    "\n",
    "    # Crear matriz binaria para las etiquetas top\n",
    "    y_pred = np.zeros(y_proba.shape[1], dtype=int)\n",
    "    for idx in top_n_indices:\n",
    "        # Solo incluir si la probabilidad supera un umbral mínimo (opcional)\n",
    "        if y_proba[0][idx] > 0.05:\n",
    "            y_pred[idx] = 1\n",
    "\n",
    "    # Convertir de matriz binaria a etiquetas\n",
    "    predicted_tags = multilabel_binarizer.inverse_transform(y_pred.reshape(1, -1))\n",
    "\n",
    "    return predicted_tags[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a88f9-3d16-49a2-8fa8-e9e85ca3b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"s3://prueba-tecnica-nequi-camilo/data/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a710b0-b6b3-4e91-a9da-166d4a3bc438",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fd5ab7-7715-4a65-a407-d51625165459",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['Title'] + \" \" + data['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6616fd798c44838",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T20:34:53.956726Z",
     "start_time": "2025-05-19T20:34:53.954217Z"
    }
   },
   "outputs": [],
   "source": [
    "X, vectorizer = col_vectorizer_tfidf(data, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0592840e8d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T20:34:53.978269Z",
     "start_time": "2025-05-19T20:34:53.975107Z"
    }
   },
   "outputs": [],
   "source": [
    "y = data['Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef8555972111fe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T20:34:54.019806Z",
     "start_time": "2025-05-19T20:34:54.016632Z"
    }
   },
   "outputs": [],
   "source": [
    "multilabel_binarizer = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab37dc01ce9aeb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T20:34:54.043409Z",
     "start_time": "2025-05-19T20:34:54.038952Z"
    }
   },
   "outputs": [],
   "source": [
    "new_y = multilabel_binarizer.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a76c7a96f4d8d07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T20:42:12.726521Z",
     "start_time": "2025-05-19T20:42:12.722589Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493bb2d7d60b33ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T20:34:56.911222Z",
     "start_time": "2025-05-19T20:34:54.063413Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"clf\", OneVsRestClassifier(\n",
    "        LogisticRegression(max_iter=300)\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54975da776f55599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T20:35:02.877333Z",
     "start_time": "2025-05-19T20:34:56.920744Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1af6362-fd4f-4268-9b6d-6c5845fb592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca07af4bc3d1f77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T20:35:05.021834Z",
     "start_time": "2025-05-19T20:35:05.018730Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(LogisticRegression(solver='liblinear'))\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769576f-9f2d-45fb-98e2-33f30d4fb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "joblib.dump(clf, \"../../../Downloads/model.joblib\")\n",
    "with tarfile.open(\"model.tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(\"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef769287-c93c-4a48-81d7-9ebe018e24e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import Session\n",
    "sess = Session()\n",
    "model_s3 = sess.upload_data(\"model.tar.gz\", \n",
    "                            bucket=\"prueba-tecnica-nequi-camilo\",\n",
    "                            key_prefix=\"model-artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12148742a687fe8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T20:37:18.563572Z",
     "start_time": "2025-05-19T20:35:05.082920Z"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker import Session\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = Session()\n",
    "role = get_execution_role()\n",
    "prefix = \"model-artifacts\"\n",
    "model_artifact = f\"s3://prueba-tecnica-nequi-camilo/{prefix}/model.tar.gz\"\n",
    "\n",
    "sklearn_model = SKLearnModel(\n",
    "    model_data=model_artifact,\n",
    "    role=role,\n",
    "    framework_version=\"0.23-1\",\n",
    "    py_version=\"py3\",\n",
    "    sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a988530f-cfa5-4a58-9dbb-7e555d032560",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn = sklearn_model.register(\n",
    "    model_package_group_name=\"PruebaTecnica\",\n",
    "    content_types=[\"tapplication/x-parquet\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"]\n",
    ")\n",
    "print(\"Registered ModelPackage ARN:\", model_package_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661ca48-2b6c-4b0d-bce5-2fc985fcc354",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sklearn_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\"\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b7182-cbd3-4882-be6a-1c120e1e068a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
